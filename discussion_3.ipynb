{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stanleyhuang12/ds542-deep-learning/blob/main/discussion_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f84cb301-244a-489c-bb35-329f2523f57f",
      "metadata": {
        "id": "f84cb301-244a-489c-bb35-329f2523f57f"
      },
      "source": [
        "# DS 542 Spring 2026 Discussion 3\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5247d59f-ba75-4e10-99d3-53fd68dfcb6e",
      "metadata": {
        "id": "5247d59f-ba75-4e10-99d3-53fd68dfcb6e"
      },
      "source": [
        "In this notebook, we will explore the use of BU's Shared Computing Cluster (SCC) by training a simple neural network on the Pima Indians Diabetes dataset.\n",
        "\n",
        "You can read more about the dataset on [our Github repo](https://github.com/DL4DS/sp2026_discussions/blob/main/datasets/pima-indians-diabetes-dataset/README.md) and on the SCC at `/projectnb/dl4ds/materials/datasets/pima-indians-diabetes-dataset/README.md`\n",
        "\n",
        "Please [discussion_3_setu.md](https://github.com/DL4DS/sp2026_discussions/blob/main/discussion_3_setup.md) for set up instructions."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "YlYImKlYHS2Z",
      "metadata": {
        "id": "YlYImKlYHS2Z"
      },
      "source": [
        "## Instructions\n",
        "\n",
        "1. Run your copy notebook in Jupyter on the SCC using at least one GPU as explained in the SCC lecture.\n",
        "2. Confirm that you have GPU access using the code below.\n",
        "3. Complete the 7 exercises included in this notebook.\n",
        "4. Submit just this notebook to Gradescope."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9555ab0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "c9555ab0",
        "outputId": "0bc41880-4260-47e3-b20a-09d98224fb1b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.9.0+cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import os\n",
        "import math\n",
        "import socket\n",
        "import psutil\n",
        "import getpass\n",
        "import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import imageio.v2 as imageio\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "torch.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wznLEFshWClB",
      "metadata": {
        "id": "wznLEFshWClB"
      },
      "source": [
        "## Part One: SCC Basics"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67567ff0-79eb-4453-a7a0-6ab714323fd8",
      "metadata": {
        "id": "67567ff0-79eb-4453-a7a0-6ab714323fd8"
      },
      "source": [
        "### Exercise 1: Create a SCC session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "659c88f8-9010-474a-b3fa-2eba19824f68",
      "metadata": {
        "id": "659c88f8-9010-474a-b3fa-2eba19824f68",
        "outputId": "d3bdd0a3-2a75-4442-a5bc-dbde37889bc0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fail.\n",
            "hostname: c50994dccb4e\n",
            "username: root\n",
            "current_time: 2026-02-06T16:17:48.819920\n",
            "python_path: /usr/lib/python3.12\n",
            "working_directory: /content\n",
            "cuda_available: False\n",
            "cuda_device_count: 0\n",
            "cpu_count: 2\n",
            "memory_total_gb: 12.67\n",
            "pytorch_version: 2.9.0+cpu\n"
          ]
        }
      ],
      "source": [
        "# TODO: run this block to verify your scc environment\n",
        "\n",
        "def verify_scc_environment():\n",
        "\n",
        "    verification_info = {\n",
        "        'hostname': socket.gethostname(),\n",
        "        'username': getpass.getuser(),\n",
        "        'current_time': datetime.datetime.now().isoformat(),\n",
        "        'python_path': os.path.dirname(os.__file__),\n",
        "        'working_directory': os.getcwd(),\n",
        "        'cuda_available': torch.cuda.is_available(),\n",
        "        'cuda_device_count': torch.cuda.device_count() if torch.cuda.is_available() else 0,\n",
        "        'cpu_count': psutil.cpu_count(),\n",
        "        'memory_total_gb': round(psutil.virtual_memory().total / (1024**3), 2),\n",
        "        'pytorch_version': torch.__version__\n",
        "    }\n",
        "\n",
        "    if 'scc' not in verification_info['hostname'].lower() and 'cluster' not in verification_info['hostname'].lower():\n",
        "        print(\"Fail.\")\n",
        "\n",
        "    for key, value in verification_info.items():\n",
        "        print(f\"{key}: {value}\")\n",
        "\n",
        "    return verification_info\n",
        "\n",
        "verify_info = verify_scc_environment()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a75b2c8b-84ff-4a37-9838-010dbbef8254",
      "metadata": {
        "id": "a75b2c8b-84ff-4a37-9838-010dbbef8254"
      },
      "source": [
        "### Exercise 2: Create a Tensor on GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4398c541-7aa4-4814-acc6-9081cc1d6577",
      "metadata": {
        "id": "4398c541-7aa4-4814-acc6-9081cc1d6577"
      },
      "outputs": [],
      "source": [
        "# TODO: create a tensor on GPU using `device='cuda:0`\n",
        "\n",
        "t_gpu = torch.tensor(\"cuda:0\")\n",
        "print(t_gpu)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "946309b2-33b1-44f1-b2ca-e37bec2400c2",
      "metadata": {
        "id": "946309b2-33b1-44f1-b2ca-e37bec2400c2"
      },
      "source": [
        "### Exercise 3: Impleting a CPU hard task on GPU device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48e40ac4-2f5d-4a3c-8543-0ebc1e4b35bc",
      "metadata": {
        "id": "48e40ac4-2f5d-4a3c-8543-0ebc1e4b35bc"
      },
      "outputs": [],
      "source": [
        "n = 10000\n",
        "i, k = 1234, 5678\n",
        "\n",
        "\n",
        "# Build A, B on GPU via broadcasting\n",
        "device = torch.device(device=\"cuda:0\")\n",
        "rows = torch.arange(1, n+1, device=device, dtype=torch.float64).view(-1, 1)\n",
        "cols = torch.arange(1, n+1, device=device, dtype=torch.float64).view(1, -1)\n",
        "\n",
        "A = rows + cols                    # A_{ij} = i + j\n",
        "B = cols.transpose(0,1) - cols     # B_{jk} = j - k\n",
        "\n",
        "\n",
        "# TODO: multiply on GPU\n",
        "C = rows @ cols  # 10k x 10k matrix multiplication, which is fast on GPU but painful on CPU.\n",
        "\n",
        "val_gpu = C[i-1, k-1].item()\n",
        "print(int(val_gpu))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7e939e3-24e9-4dcb-9022-f545136ee0bf",
      "metadata": {
        "id": "e7e939e3-24e9-4dcb-9022-f545136ee0bf"
      },
      "source": [
        "### Exercise 4: Read dataset from shared folder\n",
        "\n",
        "Read the dataset from: `/projectnb/dl4ds/materials/datasets/pima-indians-diabetes-dataset/diabetes.csv`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "119a61d5-3e0d-4bcb-8b38-fcbdb7668cca",
      "metadata": {
        "id": "119a61d5-3e0d-4bcb-8b38-fcbdb7668cca"
      },
      "outputs": [],
      "source": [
        "# TODO: run this block to import the CSV file from the shared folder\n",
        "\n",
        "df = pd.read_csv(\"/projectnb/dl4ds/materials/datasets/pima-indians-diabetes-dataset/diabetes.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0dd7f4ec-2bf1-42a8-b07b-c8ca99632589",
      "metadata": {
        "id": "0dd7f4ec-2bf1-42a8-b07b-c8ca99632589"
      },
      "source": [
        "### Exercise 5: Train a Neural Network with above dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6744e8d4-3440-448e-b13a-0bab55ee3136",
      "metadata": {
        "id": "6744e8d4-3440-448e-b13a-0bab55ee3136"
      },
      "outputs": [],
      "source": [
        "X = torch.tensor(df.drop(\"Outcome\", axis=1).values, dtype=torch.float32)\n",
        "y = torch.tensor(df[\"Outcome\"].values, dtype=torch.float32).view(-1,1)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "# define a 2-layer NN\n",
        "class ShallowNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(X.shape[1], 8)\n",
        "        self.fc2 = nn.Linear(8, 2)\n",
        "        self.fc3 = nn.Linear(2, 1)\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        return torch.sigmoid(self.fc3(x))\n",
        "\n",
        "\n",
        "#TODO: optimize/run the model by changing any params\n",
        "model = ShallowNN()\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.1)\n",
        "\n",
        "losses_nn = []\n",
        "\n",
        "\n",
        "# Training\n",
        "for epoch in range(5):\n",
        "    optimizer.zero_grad()\n",
        "    output = model(X_train)\n",
        "    loss = criterion(output, y_train)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    losses_nn.append(loss.item())\n",
        "\n",
        "# Predictions on the full dataset\n",
        "with torch.no_grad():\n",
        "    final_predictions_nn = model(X)\n",
        "\n",
        "# Accuracy\n",
        "predicted_classes_nn = (final_predictions_nn > 0.5).float()\n",
        "accuracy_nn = (predicted_classes_nn == y).float().mean()\n",
        "print(f\"Neural Network Accuracy: {accuracy_nn:.4f}\")\n",
        "\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.plot(losses_nn)\n",
        "plt.title('Neural Network Training Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "CJUDB9EtK5PZ",
      "metadata": {
        "id": "CJUDB9EtK5PZ"
      },
      "source": [
        "## Part Two: Train and Analyze a Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "jqUljVc7HOSL",
      "metadata": {
        "id": "jqUljVc7HOSL"
      },
      "source": [
        "### Background\n",
        "\n",
        "This notebook builds a model detecting trees in images.\n",
        "The data set consists of roughly 500 pictures and is currently stored in `/projectnb/dl4ds/materials/datasets/tree-or-not` on the SCC.\n",
        "Most of them are from the Boston area, but some are from around the globe.\n",
        "Most of them were taken outside, but some were taken inside or in more exotic locations.\n",
        "Many other factors such as lighting, weather, and confounding bushes will make this a challenging problem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ctqAfRIkHRMh",
      "metadata": {
        "id": "ctqAfRIkHRMh"
      },
      "outputs": [],
      "source": [
        "def to_gpu(t):\n",
        "    if torch.cuda.is_available():\n",
        "        return t.cuda()\n",
        "    return t\n",
        "\n",
        "def to_numpy(t):\n",
        "    return t.detach().cpu().numpy()\n",
        "\n",
        "device = to_gpu(torch.ones(1,1)).device\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "gCN4o9zAHtPd",
      "metadata": {
        "id": "gCN4o9zAHtPd"
      },
      "source": [
        "### Exercise 6: Load Data\n",
        "\n",
        "This code originally relied on checking out or cloning [this repository](https://github.com/dl4ds/fa2024_midterm)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "uCO-HBgdHujE",
      "metadata": {
        "id": "uCO-HBgdHujE"
      },
      "outputs": [],
      "source": [
        "# TODO;\n",
        "# - Modify this code to load from `/projectnb/dl4ds/materials/datasets/tree-or-not` (this will be the base_dir).\n",
        "# - Set your image width to be 64 for faster training\n",
        "# - Call the load_data_set function on both \"train\" and \"validation\"\n",
        "\n",
        "image_width = 64\n",
        "base_dir = \"/projectnb/dl4ds/materials/datasets/tree-or-not\"\n",
        "\n",
        "def load_data_set(data_set_name):\n",
        "    labels_path = os.path.join(base_dir, f\"{data_set_name}.tsv\")\n",
        "    labels = pd.read_csv(labels_path, sep=\"\\t\")\n",
        "\n",
        "    file_names = []\n",
        "    images = []\n",
        "    targets = []\n",
        "    for i in range(labels.shape[0]):\n",
        "        row = labels.iloc[i]\n",
        "        image_path = os.path.join(base_dir, f\"images{image_width}\", row[\"filename\"])\n",
        "        try:\n",
        "            image = imageio.imread(image_path)\n",
        "        except:\n",
        "            print(\"SKIPPING \", row['filename'], \"MISSING\")\n",
        "            continue\n",
        "\n",
        "        if image.shape[0] != image.shape[1] * 3 // 4:\n",
        "            print(\"SKIPPING \", row['filename'], image.shape)\n",
        "            continue\n",
        "\n",
        "        # convert from 0-255 to 0.0-1.0\n",
        "        image = image / 255\n",
        "        # prepend axis with length one\n",
        "        # image = image.reshape(1, *image.shape)\n",
        "        image = torch.tensor(image, device=device, dtype=torch.float32)\n",
        "        # permute image dimensions to put color channel first\n",
        "        image = torch.permute(image, [2, 0, 1])\n",
        "\n",
        "        file_names.append(row['filename'])\n",
        "        images.append(image)\n",
        "        targets.append(row[\"target\"])\n",
        "\n",
        "    images = torch.stack(images)\n",
        "\n",
        "    targets = torch.tensor(targets, device=device, dtype=torch.float32)\n",
        "    targets = targets.long()\n",
        "\n",
        "    return (file_names, images, targets)\n",
        "\n",
        "train_data_set = load_data_set(\"train.tsv\")\n",
        "for t in train_data_set[1:]:\n",
        "    print(\"TRAIN\", t.shape, t.dtype, t.device)\n",
        "(train_file_names, train_X, train_Y) = train_data_set\n",
        "\n",
        "validation_data_set = load_data_set(\"validation.tsv\")\n",
        "for t in validation_data_set[1:]:\n",
        "    print(\"VALIDATION\", t.shape, t.dtype, t.device)\n",
        "(validation_file_names, validation_X, validation_Y) = validation_data_set"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Gix2RiK8Iywq",
      "metadata": {
        "id": "Gix2RiK8Iywq"
      },
      "source": [
        "Run the following cell to preview one of the images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "SEG27y_UIuav",
      "metadata": {
        "id": "SEG27y_UIuav"
      },
      "outputs": [],
      "source": [
        "plt.imshow(to_numpy(torch.permute(train_X[0,:,:,:], (1, 2, 0))))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bcABWiHlKd9z",
      "metadata": {
        "id": "bcABWiHlKd9z"
      },
      "source": [
        "### Model Building\n",
        "\n",
        "Run the following code cells. Do not modify any of this code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hnP7QNA3Kc6J",
      "metadata": {
        "id": "hnP7QNA3Kc6J"
      },
      "outputs": [],
      "source": [
        "class TreeNetwork(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv_0 = torch.nn.Conv2d(in_channels=3, out_channels=5, kernel_size=5, stride=2, device=device)\n",
        "        self.conv_1 = torch.nn.Conv2d(in_channels=5, out_channels=5, kernel_size=3, stride=2, device=device)\n",
        "        self.conv_2 = torch.nn.Conv2d(in_channels=5, out_channels=5, kernel_size=1, device=device)\n",
        "        self.fc_3 = torch.nn.Linear(700, 2)\n",
        "\n",
        "        self.relu = torch.nn.ReLU()\n",
        "\n",
        "    def forward(self, X):\n",
        "\n",
        "        X = self.conv_0(X)\n",
        "        X = self.relu(X)\n",
        "\n",
        "        X = self.conv_1(X)\n",
        "        X = self.relu(X)\n",
        "\n",
        "        X = self.conv_2(X)\n",
        "        X = self.relu(X)\n",
        "\n",
        "        # flatten channels and image dimensions\n",
        "        X = X.reshape(X.shape[:-3] + (-1,))\n",
        "\n",
        "        X = self.fc_3(X)\n",
        "\n",
        "        return X\n",
        "\n",
        "test_model = TreeNetwork().to(device)\n",
        "test_output = test_model(train_X[:5,:,:,:])\n",
        "assert test_output.shape == (5, 2)\n",
        "del test_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pmQftJ8lKhFD",
      "metadata": {
        "id": "pmQftJ8lKhFD"
      },
      "outputs": [],
      "source": [
        "loss_function = torch.nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "I4nw_hzFKifa",
      "metadata": {
        "id": "I4nw_hzFKifa"
      },
      "outputs": [],
      "source": [
        "DEFAULT_EPOCHS = 1000 if torch.cuda.is_available() else 100\n",
        "\n",
        "def train_model(model_class, epochs=DEFAULT_EPOCHS, learning_rate=1e-4, **kwargs):\n",
        "    model = model_class(**kwargs)\n",
        "    try:\n",
        "        model = model.cuda()\n",
        "    except:\n",
        "        print(\"cuda() failed\")\n",
        "    model = torch.nn.DataParallel(model)\n",
        "    model.train()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    for i in range(epochs):\n",
        "        model.train()\n",
        "\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        prediction = model(train_X)\n",
        "        loss = loss_function(prediction, train_Y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i + 1) % 50 == 0:\n",
        "            liveloss_updates = {}\n",
        "            with torch.no_grad():\n",
        "                model.eval()\n",
        "\n",
        "                metrics = {}\n",
        "                def get_metrics(metrics_prefix, metrics_X, metrics_Y):\n",
        "                    metrics_prediction = model(metrics_X)\n",
        "\n",
        "                    return {\n",
        "                        f\"{metrics_prefix}loss\": loss_function(metrics_prediction, metrics_Y)\n",
        "                    }\n",
        "\n",
        "                metrics.update(get_metrics(\"train_\", train_X, train_Y))\n",
        "                metrics.update(get_metrics(\"val_\", validation_X, validation_Y))\n",
        "                print(\"ITER\", i+1, \"METRICS\", metrics)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "P_2hQfIRKwa0",
      "metadata": {
        "id": "P_2hQfIRKwa0"
      },
      "outputs": [],
      "source": [
        "tree_model = train_model(TreeNetwork, epochs=2000)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "QieaF97YKoKL",
      "metadata": {
        "id": "QieaF97YKoKL"
      },
      "source": [
        "## Exercise 7: Question\n",
        "\n",
        "Review the metrics printed above while training the model.\n",
        "What trends do you notice in the training and validation losses?\n",
        "Just state the trends that you see.\n",
        "You do not need to explain them."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3fsU6g7wKtdO",
      "metadata": {
        "id": "3fsU6g7wKtdO"
      },
      "source": [
        "TODO:\n",
        "YOUR ANSWER HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Sgnl9McwKo3r",
      "metadata": {
        "id": "Sgnl9McwKo3r"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}